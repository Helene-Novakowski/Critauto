#Projet/Produit


#vider la mémoire
rm(list = ls())


#Library
library("DescTools")# Pour la visualisation des données manquantes
library(dplyr)
library(tidyverse) #Pour ggplot
library(nnet)
library('Hmisc') #pour describe
library(MASS)
library(glmnet)




# chemin vers le répertoire courant où est placé le fichier de données
setwd("C:/Users/damien/Desktop/Cours/Mathematiques/M2/Gestion_de_Projet_Digitalise/Produit/bdd")

## Importation du fichier
# CO2 <- read.xlsx("bdd_CO2.csv", sheetIndex = 1, 
#                    header = TRUE, stringsAsFactors = TRUE)
# library(readr)
CO2 <- read.csv2("C:/Users/damien/Desktop/Cours/Mathematiques/M2/Gestion_de_Projet_Digitalise/Produit/bdd/bdd_CO2.csv", stringsAsFactors=TRUE)

##### Modèle de régression logistique binomial pour la classification binaire #####

#vérifications
str(CO2)
View(CO2)

#quelques statistiques
summary(CO2)

# calculating the product of dimensions of dataframe 
totalcells = prod(dim(CO2)) #nombre total de cellule est de 143144

# calculating the number of cells with na
missingcells = sum(is.na(CO2)) #nombre de cellule na est de 58307

# calculating percentage of missing values
percentage = (missingcells * 100 )/(totalcells) #pourcentage de na est de 4.074153


####################################################################################################################################
#### Modèle de régression logistique binomial####
####################################################################################################################################
CO2 %>% 
  mutate(var_co2 = ifelse(co2 > 200,"pollution","correct")) %>%
  dplyr::select(-co2, -dscom, -hybride,-hc, -nox) -> don

# nrow(don)
na.omit(don) -> don  #On retire toutes les données manquantes !
as.factor(don$var_co2) -> don$var_co2



#faire une régression logistique de la variable binaire co2 en fonction des variables (explicatives) 
#de la bd CO2 : 
# modele.RL <- glm(formula = var_co2 ~ lib_mrq+lib_mod_doss+lib_mod+cnit+tvv+cod_cbr+puiss_admin_98+puiss_max+
#                    typ_boite_nb_rapp+conso_urb+conso_exurb+conso_mixte+co_typ_1+hcnox+ptcl+masse_ordma_min+
#                    masse_ordma_max+champ_v9+date_maj+Carrosserie+gamme,  data = don, family = binomial) #Trop grand
# print(modele.RL)
# summary(modele.RL)
# attributes(modele.RL)
# View(CO2)

modele.RL <- glm(formula = var_co2 ~ cod_cbr+puiss_admin_98+typ_boite_nb_rapp+conso_exurb+Carrosserie+gamme, family = binomial,  data = don)
print(modele.RL)
summary(modele.RL)
attributes(modele.RL)





####################################################################################################################################
#### Modification de la base pour multinomial
####################################################################################################################################

summary(CO2)

CO2 %>% 
  mutate(var_co2 = ifelse(co2 < 175,"faible",ifelse(co2 < 225, "moyenne","forte"))) %>%
  dplyr::select(-co2, -dscom, -hybride,-hc, -nox) -> CO2_mod

colnames(CO2_mod)
miss <- data.frame(CO2_mod)
colnames(miss) <- c("la marque","le modele du dossier","le modèle commercial",
                    "le Code National d'Identification du Type (CNIT)", 
                    "le Type-Variante-Version (TVV) ou le type Mines","le type de carburant",
                    "la puissance administrative","la puissance maximale (en kW)",
                    "le type de boîte de vitesse et le nombre de rapports",
                    "consommation urbaine de carburant (en l/100km)",
                    "consommation mixte de carburant (en l/100km)",
                    "consommation extra urbaine de carburant (en l/100km)",
                    "le résultat d’essai de CO type I",
                    "les résultats d’essai HC+NOX",
                    "le résultat d’essai de particules",
                    "la masse en ordre de marche mini",
                    "la masse en ordre de marche maxi",
                    "le champ V9 du certificat d’immatriculation qui contient la norme EURO",
                    "la date de la dernière mise à jour",
                    "Carrosserie","gamme",
                    "Statut de pollution par émission de CO2 (en g/km)")
# View(miss)
####Données manquantes :
length(which(is.na(miss)))
# PlotMiss(miss, main = "Données manquantes") 
#en baton rouge c'est une données manquantes

na.omit(CO2_mod) -> data_co2  #On retire toutes les données manquantes !
as.factor(data_co2$var_co2) -> data_co2$var_co2
# colnames(data_co2)
ncol(data_co2)
# View(data_co2)
# describe(data_co2)

totalcells_mod = prod(dim(data_co2)) #nombre total de cellule est de 993322
((totalcells -totalcells_mod )*100)/ totalcells #on a retiré 30% de la base initial

totalcells = prod(dim(CO2_mod)) #nombre total de cellule est de 993322
((totalcells -totalcells_mod )*100)/ totalcells #on a retiré 18% par sélection de lignes sans données manquantes sur la base conennant certaines colonnes




####################################################################################################################################
#### Modèle de régression logistique multinomial pour la classification multi-groupe ####
####################################################################################################################################

#Pour éviter le sur-apprentissage!

XX <- model.matrix(var_co2 ~cod_cbr+puiss_admin_98+typ_boite_nb_rapp+conso_exurb+Carrosserie+gamme, data = data_co2)[,-1] #Cette fonction construit la matrice de design en remplaçant 
#chacune des variables qualitatives par les indicatrices 
#de ses modalités (la première modalité est supprimée)
#on supprime la première colonne correspondant à l'intercept
# View(XX)
data_co2 <- cbind(as.data.frame(XX), var_co2 = as.factor(data_co2[,"var_co2"])) #bd constituée que de variables explicatives numériques 
# View(data_co2)




# Nous avons un grandnombre de variable explicatives
#Nous allons faire une pré- sélection avec le lasso avant d'utiliser des méthodes de sélection de modèle


#### Régression logistique multinomial Lasso ####
reg.lasso <- glmnet(x = scale(data_co2[, !(colnames(data_co2) == "var_co2")]), 
                    y = data_co2[, "var_co2"], family = "multinomial", 
                    type.multinomial = "grouped", alpha = 1)

# par(mfrow = c(1,1))
plot(reg.lasso, label = TRUE)
plot(reg.lasso, xvar = "lambda", label = TRUE, lwd = 2)
reg.cvlasso <- cv.glmnet(x = scale(data_co2[, !(colnames(data_co2) == "var_co2")]), 
                         y = data_co2[, "var_co2"], family = "multinomial",
                         type.measure = "class", 
                         type.multinomial = "grouped", 
                         nflods = nrow(data_co2), alpha = 1)

bestlam <- reg.cvlasso$lambda.min
bestlam
plot(reg.cvlasso)
min(reg.cvlasso$cvm) #erreur de classification du modèle lasso optimal 
#coef(reg.cvlasso)

indices <- !(coef(reg.cvlasso)[[2]]  == 0)
indices.var.select <- indices[2:length(indices)]
#les variables explicatives sélectionnées par le lasso
noms.var.lasso <- colnames(data_co2[, !(colnames(data_co2) == "var_co2")])[indices.var.select]

co2.data2 <- data_co2[, noms.var.lasso]
co2.data2 <- as.data.frame(cbind(co2.data2, var_co2 = data_co2$var_co2))
str(co2.data2)

View(co2.data2)
summary(co2.data2)
# colnames(co2.data)


# #variable réponse : var_co2
# #variables explicatives (numériques) : typ_boite_nb_rappA 5 + typ_boite_nb_rappA 6 + typ_boite_nb_rappA 8 + conso_exurb + 
# CarrosserieCOMBISPACE + CarrosserieMINIBUS + CarrosserieTS TERRAINS/CHEMINS + gammeLUXE




#la fonction multinom() calcule les estimateurs des paramètres,
#du model de RegLogMultinomial, par maximum de vraisemblance;
#maxit : est le nombre maximal d'itérations pour le calcul des estimateurs MV
modele.complet <- multinom(formula = var_co2 ~ ., data = co2.data2, model = TRUE, maxit = 1000)
print(modele.complet)
print(summary(modele.complet))
attributes(modele.complet)
modele.complet$edf #donne le nombre de paramètres du modèle de RegLogMultinomial
formula(modele.complet$model)

# var_co2 ~ `typ_boite_nb_rappA 5` + `typ_boite_nb_rappA 6` + conso_exurb + 
#   CarrosserieCOMBISPACE + CarrosserieMINIBUS + `CarrosserieTS TERRAINS/CHEMINS` + 
#   gammeLUXE

modele.trivial <- multinom(formula = var_co2 ~ 1, data = co2.data2, model = TRUE, maxit = 3000)
print(modele.trivial)
print(summary(modele.trivial))
modele.trivial$edf
attributes(modele.trivial)
formula(modele.trivial$model)

# var_co2 ~ 1



################################################################################################################"
#### Sélection de modèles (de variables) selon le critère AIC par algorithmes de recherche pas-à-pas ####


#la méthode backward elimination
modele.back <- step(object = modele.complet,
                    scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                    direction = "backward") #par défaut critère AIC
modele.back
formula(modele.back$model) #le modèle optimal obtenu

#le meilleur modèle est complet


#la méthode forward selection
modele.forward <- step(object = modele.trivial,
                       scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                       direction = "forward")
modele.forward
formula(modele.forward$model) #le modèle optimal obtenu

#on cherche la var qui fait baisser le + le critère AIC
# on a le modèle complet


#la méthode bidirectional elimination / combine backward et forward
modele.bidirect.elim <- step(object = modele.complet,
                             scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                             direction = "both")
modele.bidirect.elim
formula(modele.bidirect.elim$model) #le modèle optimal obtenu

# on a le modèle complet

#la méthode bidirectional selection / on commence par le modèle trivial, ascendante
modele.bidirect.select <- step(object = modele.trivial,
                               scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                               direction = "both")
modele.bidirect.select
formula(modele.bidirect.select$model) #le modèle optimal obtenu

# Modèle complet

#les 4 algorithmes précédents donne le même modèle  complet!



#### Sélection de modèles (de variables) selon le critère BIC par algorithmes de recherche pas-à-pas ####
n <- nrow(co2.data2) #nombre d'observation

#la méthode backward elimination
modele.back <- step(object = modele.complet,
                    scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                    direction = "backward", k = log(n))
modele.back
formula(modele.back$model) #le modèle optimal obtenu

# Modèle complet


#la méthode forward selection
modele.forward <- step(object = modele.trivial,
                       scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                       direction = "forward", k = log(n))
modele.forward
formula(modele.forward$model) #le modèle optimal obtenu

# var_co2 ~ conso_exurb + `typ_boite_nb_rappA 5` + `CarrosserieTS TERRAINS/CHEMINS` + 
#   gammeLUXE + CarrosserieCOMBISPACE


#la méthode bidirectional elimination
modele.bidirect.elim <- step(object = modele.complet,
                             scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                             direction = "both", k = log(n))
modele.bidirect.elim
formula(modele.bidirect.elim$model) #le modèle optimal obtenu

# Modèle complet

#la méthode bidirectional selection
modele.bidirect.select <- step(object = modele.trivial,
                               scope = list(lower = var_co2 ~ 1, upper = formula(modele.complet$model)),
                               direction = "both", k = log(n))
modele.bidirect.select
formula(modele.bidirect.select$model) #le modèle optimal obtenu

# var_co2 ~ conso_exurb + `typ_boite_nb_rappA 5` + `CarrosserieTS TERRAINS/CHEMINS` + 
#   gammeLUXE + CarrosserieCOMBISPACE

# Les deux critères AIC et BIC donne le même modèle. (à l'exception du BIC selection)








#################################################################################
#var la + significative est celle dont la p-value est la + faible
################################################################################################################"


#### Tests d'hypothèses par maximum de vraisemblance dans le modèle de RegLogMultinom ####
#Nous allons considérer le modèle optimal sélectionné selon le critère AIC
#on crée d'abord le sous-ensemble de données correspondantù

# View(data_co2)
# ncol(data_co2)
co2.data2 %>%
  dplyr::select(var_co2, conso_exurb, `typ_boite_nb_rappA 5`,
           `CarrosserieTS TERRAINS/CHEMINS`, `gammeMOY-SUPER`, gammeLUXE, CarrosserieCOMBISPACE, `typ_boite_nb_rappA 8`) -> opt.data
View(opt.data)
ncol(opt.data)
# opt.data <- data.frame(co2.data2)

#### Test de validité du modèle global : H_0 : w_2 = w_3 = (0,0,0) ####
modele <-  multinom(formula = var_co2 ~  ., data = opt.data, maxit = 3000)  #déviance du modèle global
modele.reduit <- multinom(formula = var_co2 ~ 1, data = opt.data, maxit = 3000)  #déviance du modèle réduit

Sn <- modele.reduit$deviance-modele$deviance #la statistique du rapport de vraisemblance
print(Sn) #51287.8
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
#nb de paramère du modèle, 3 var +1 + 2 modalité donc 8 -2=6
#d différence des 2 dimensions (=nb de paramètre)

pvalue <- pchisq(q = Sn, df = d, lower.tail = F)
print(pvalue) #on obtient 0, le modèle optimal est très significatif



#### Tester si la variable conso_exurb n'est pas significative dans le modèle : H_0 : w_{2,1} = w_{3,1} = 0 ####
#H0 la variable x_1 n'est pas significative dans le modèle
#le modèle réduit exclu la variable x1
modele <-  multinom(formula = var_co2 ~  ., data = opt.data, maxit = 3000) 
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="conso_exurb")], 
                          maxit = 2000) #le modèle réduit
Sn.conso_exurb <- modele.reduit$deviance - modele$deviance
print(Sn.conso_exurb)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.conso_exurb <- pchisq(q = Sn.conso_exurb, df = d, lower.tail = F)
print(pvalue.conso_exurb)


#Tester si la variable `typ_boite_nb_rappA 5` n'est pas significative : H_0 = w_{2,2} = w_{3,2} = 0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="typ_boite_nb_rappA 5" )], 
                          maxit = 2000) #le modèle réduit
Sn.typ_boite_nb_rappA_5 <- modele.reduit$deviance - modele$deviance
print(Sn.typ_boite_nb_rappA_5)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.typ_boite_nb_rappA_5 <- pchisq(q = Sn.typ_boite_nb_rappA_5, df = d, lower.tail = F)
print(pvalue.typ_boite_nb_rappA_5)


#Tester si la variable `typ_boite_nb_rappA 8` n'est pas significative : H_0 = w_{2,2} = w_{3,2} = 0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="typ_boite_nb_rappA 8" )], 
                          maxit = 2000) #le modèle réduit
Sn.typ_boite_nb_rappA_8 <- modele.reduit$deviance - modele$deviance
print(Sn.typ_boite_nb_rappA_8)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.typ_boite_nb_rappA_8 <- pchisq(q = Sn.typ_boite_nb_rappA_8, df = d, lower.tail = F)
print(pvalue.typ_boite_nb_rappA_8)

#Tester si la variable `CarrosserieTS TERRAINS/CHEMINS` n'est pas significative : H_0 = w_{2,4}=w_{3,4}=0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="CarrosserieTS TERRAINS/CHEMINS")], 
                          maxit = 2000) #le modèle réduit
Sn.CarrosserieTS_TERRAINS_CHEMINS <- modele.reduit$deviance - modele$deviance
print(Sn.CarrosserieTS_TERRAINS_CHEMINS)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.CarrosserieTS_TERRAINS_CHEMINS <- pchisq(q = Sn.CarrosserieTS_TERRAINS_CHEMINS, df = d, lower.tail = F)
print(pvalue.CarrosserieTS_TERRAINS_CHEMINS)


#Tester si la variable gammeLUXE n'est pas significative : H_0 = w_{2,5}=w_{3,5}=0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="gammeLUXE")], 
                          maxit = 2000) #le modèle réduit
Sn.gammeLUXE <- modele.reduit$deviance - modele$deviance
print(Sn.gammeLUXE)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.gammeLUXE <- pchisq(q = Sn.gammeLUXE, df = d, lower.tail = F)
print(pvalue.gammeLUXE)


#Tester si la variable gammeMOY-SUPER n'est pas significative : H_0 = w_{2,5}=w_{3,5}=0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="gammeMOY-SUPER")], 
                          maxit = 2000) #le modèle réduit
Sn.gammeMOY_SUPER <- modele.reduit$deviance - modele$deviance
print(Sn.gammeMOY_SUPER)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.gammeMOY_SUPER <- pchisq(q = Sn.gammeMOY_SUPER, df = d, lower.tail = F)
print(pvalue.gammeMOY_SUPER)

#Tester si la variable `CarrosserieCOMBISPACE COMPACT` n'est pas significative : H_0 = w_{2,5}=w_{3,5}=0
modele.reduit <- multinom(formula = var_co2 ~ ., 
                          data = opt.data[, !(colnames(opt.data)=="CarrosserieCOMBISPACE")], 
                          maxit = 2000) #le modèle réduit
Sn.CarrosserieCOMBISPACE <- modele.reduit$deviance - modele$deviance
print(Sn.CarrosserieCOMBISPACE)
d <- modele$edf - modele.reduit$edf  #donne le n ddl de la loi du chi2 asymptotique de la stat Sn
pvalue.CarrosserieCOMBISPACE <- pchisq(q = Sn.CarrosserieCOMBISPACE, df = d, lower.tail = F)
print(pvalue.CarrosserieCOMBISPACE)


##+ var significative + Sn est grand
#### Classer les variables ####
pvalues <- c(pvalue.conso_exurb, pvalue.typ_boite_nb_rappA_5, pvalue.typ_boite_nb_rappA_8,
             pvalue.CarrosserieTS_TERRAINS_CHEMINS, pvalue.gammeLUXE, pvalue.gammeMOY_SUPER, pvalue.CarrosserieCOMBISPACE)
length(pvalues)
names(pvalues) <- colnames(opt.data[, !(colnames(opt.data) == "var_co2")])
variables.classees <- sort(pvalues)
print(variables.classees) # on obtient le classement suivant :

#Et pour Sn
Sn <- c(Sn.conso_exurb, Sn.typ_boite_nb_rappA_5, Sn.typ_boite_nb_rappA_8,
             Sn.CarrosserieTS_TERRAINS_CHEMINS, Sn.gammeLUXE, Sn.gammeMOY_SUPER, Sn.CarrosserieCOMBISPACE)
length(Sn)
names(Sn) <- colnames(opt.data[, !(colnames(opt.data) == "var_co2")])
variables.classees2 <- rev(sort(Sn))
print(variables.classees2) # on obtient le classement suivant :



#################################################################################################

#### Erreurs de classification, évaluées par validation croisées, 
#pour le modèle optimal selon BIC (réduit aux trois variables Sepal.Width, Petal.Length et Petal.Width),  
#et pour le modèle complet utilisant les quatre variables #### 
indices <- 1:nrow(co2.data2)
#la fonction évaluant l'erreur de classification des deux modèles, pour une partition donnée
err_classif <- function(l = 3){
  #on partage le tableau en deux parties : par exemple (l-1)/l pour apprentissage et 1/l pour le test
  indices.ensemble.test <- sample(indices, trunc(length(indices)/l), replace = FALSE)
  ensemble.test <- co2.data2[indices.ensemble.test, ]
  ensemble.apprentissage <- co2.data2[-indices.ensemble.test, ]
  modele.BIC <- multinom(formula = var_co2 ~ conso_exurb + `typ_boite_nb_rappA 5` + `typ_boite_nb_rappA 8` +
                           `CarrosserieTS TERRAINS/CHEMINS` +  `gammeMOY-SUPER` + gammeLUXE + CarrosserieCOMBISPACE,
                         data = ensemble.apprentissage, maxit = 3000) # le modèle optimal
  modele.complet <- multinom(formula = var_co2 ~ ., 
                             data = ensemble.apprentissage, maxit = 3000) # le modèle complet
  pred.moda.modele.AIC <- predict(object = modele.BIC, newdata = ensemble.test)
  pred.moda.modele.complet <- predict(object = modele.complet, newdata = ensemble.test)
  erreur.modele.BIC <- mean(!(pred.moda.modele.BIC == ensemble.test$var_co2)) #pourcentage des indiv sur l'ensemble des test pour lesquels on s'est trompé
  erreur.modele.complet <- mean(!(pred.moda.modele.complet == ensemble.test$var_co2))   
  return(c(erreur.modele.BIC, erreur.modele.complet))
}  

print(err_classif(3)) #premier est pour le modèle réduit, l'autre le modèle complet


#il faut le faire plusieurs fois ici 100

#on applique la fonction précédente M = 100 fois, à l'aide de la fonction ``replicate'', 
#et on met les résultats dans le tableau resultats, de dimension 2xM,
#cela évite l'utilisation de boucles for. 
M <- 100 #nombre de réplications
resultats <- replicate(M, err_classif(3))
resutats.moyens <- apply(resultats,1,mean) #on calcule la moyenne par colonne
err.classif.modele.BIC <- resutats.moyens[1]
err.classif.modele.complet <- resutats.moyens[2]
err.classif.modele.BIC #0.007186047
err.classif.modele.complet #0.00795814

#la plus faible erreur parmi les 2 nous donne le modèle qui prédit le mieux

#on obtient des résultats comparables, pour cet exemple, l'erreur de classification est de 4% en moyenne pour les deux modèles,
#le modèle optimal est quand même mieux, car utilise peu de variables, par rapport au modèle complet, et prédit avec efficacité comparable ...




# metrics.confusion_matrix(y_true, y_pred)











